{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = pd.read_csv(\"../Data/2018-06-06-ss.cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>chain_code</th>\n",
       "      <th>seq</th>\n",
       "      <th>sst8</th>\n",
       "      <th>sst3</th>\n",
       "      <th>len</th>\n",
       "      <th>has_nonstd_aa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1A30</td>\n",
       "      <td>C</td>\n",
       "      <td>EDL</td>\n",
       "      <td>CBC</td>\n",
       "      <td>CEC</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1B05</td>\n",
       "      <td>B</td>\n",
       "      <td>KCK</td>\n",
       "      <td>CBC</td>\n",
       "      <td>CEC</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1B0H</td>\n",
       "      <td>B</td>\n",
       "      <td>KAK</td>\n",
       "      <td>CBC</td>\n",
       "      <td>CEC</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1B1H</td>\n",
       "      <td>B</td>\n",
       "      <td>KFK</td>\n",
       "      <td>CBC</td>\n",
       "      <td>CEC</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1B2H</td>\n",
       "      <td>B</td>\n",
       "      <td>KAK</td>\n",
       "      <td>CBC</td>\n",
       "      <td>CEC</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393727</th>\n",
       "      <td>4UWE</td>\n",
       "      <td>D</td>\n",
       "      <td>MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...</td>\n",
       "      <td>CCCCCCCCCCCCCCBTTCEEEEEEEEEETTEEEEEEEECCCSSCCB...</td>\n",
       "      <td>CCCCCCCCCCCCCCECCCEEEEEEEEEECCEEEEEEEECCCCCCCE...</td>\n",
       "      <td>5037</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393728</th>\n",
       "      <td>5J8V</td>\n",
       "      <td>A</td>\n",
       "      <td>MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...</td>\n",
       "      <td>CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...</td>\n",
       "      <td>5037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393729</th>\n",
       "      <td>5J8V</td>\n",
       "      <td>B</td>\n",
       "      <td>MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...</td>\n",
       "      <td>CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...</td>\n",
       "      <td>5037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393730</th>\n",
       "      <td>5J8V</td>\n",
       "      <td>C</td>\n",
       "      <td>MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...</td>\n",
       "      <td>CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...</td>\n",
       "      <td>5037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393731</th>\n",
       "      <td>5J8V</td>\n",
       "      <td>D</td>\n",
       "      <td>MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...</td>\n",
       "      <td>CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...</td>\n",
       "      <td>5037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393732 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pdb_id chain_code                                                seq  \\\n",
       "0        1A30          C                                                EDL   \n",
       "1        1B05          B                                                KCK   \n",
       "2        1B0H          B                                                KAK   \n",
       "3        1B1H          B                                                KFK   \n",
       "4        1B2H          B                                                KAK   \n",
       "...       ...        ...                                                ...   \n",
       "393727   4UWE          D  MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...   \n",
       "393728   5J8V          A  MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...   \n",
       "393729   5J8V          B  MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...   \n",
       "393730   5J8V          C  MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...   \n",
       "393731   5J8V          D  MGDGGEGEDEVQFLRTDDEVVLQCSATVLKEQLKLCLAAEGFGNRL...   \n",
       "\n",
       "                                                     sst8  \\\n",
       "0                                                     CBC   \n",
       "1                                                     CBC   \n",
       "2                                                     CBC   \n",
       "3                                                     CBC   \n",
       "4                                                     CBC   \n",
       "...                                                   ...   \n",
       "393727  CCCCCCCCCCCCCCBTTCEEEEEEEEEETTEEEEEEEECCCSSCCB...   \n",
       "393728  CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...   \n",
       "393729  CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...   \n",
       "393730  CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...   \n",
       "393731  CCCCCCCCCCCCCCCSSSCCEEEECSEETTEECCEECCEEETTEEE...   \n",
       "\n",
       "                                                     sst3   len  has_nonstd_aa  \n",
       "0                                                     CEC     3          False  \n",
       "1                                                     CEC     3          False  \n",
       "2                                                     CEC     3          False  \n",
       "3                                                     CEC     3          False  \n",
       "4                                                     CEC     3          False  \n",
       "...                                                   ...   ...            ...  \n",
       "393727  CCCCCCCCCCCCCCECCCEEEEEEEEEECCEEEEEEEECCCCCCCE...  5037           True  \n",
       "393728  CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...  5037          False  \n",
       "393729  CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...  5037          False  \n",
       "393730  CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...  5037          False  \n",
       "393731  CCCCCCCCCCCCCCCCCCCCEEEECCEECCEECCEECCEEECCEEE...  5037          False  \n",
       "\n",
       "[393732 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(sequence):\n",
    "    s = set(list(sequence))\n",
    "    if len(s)==1:\n",
    "        letter = s.pop()\n",
    "        if letter == \"*\": \n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = proteins[\n",
    "    (proteins[\"len\"]>=1) &\n",
    "    (proteins[\"len\"]<=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample[[\"seq\",\"sst3\",\"sst8\"]]\n",
    "sample = sample.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"remove\"] = sample[\"seq\"].apply(remove_empty) \n",
    "sample = sample[sample[\"remove\"]==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>sst3</th>\n",
       "      <th>sst8</th>\n",
       "      <th>remove</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDL</td>\n",
       "      <td>CEC</td>\n",
       "      <td>CBC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KCK</td>\n",
       "      <td>CEC</td>\n",
       "      <td>CBC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KAK</td>\n",
       "      <td>CEC</td>\n",
       "      <td>CBC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KFK</td>\n",
       "      <td>CEC</td>\n",
       "      <td>CBC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KMK</td>\n",
       "      <td>CEC</td>\n",
       "      <td>CBC</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61918</th>\n",
       "      <td>MAVKTGIAIGLNKGKKVTQMTPAPKISYKKGAASNRTKFVRSLVRE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHH...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCSCCCCCHHHHHHHHHHHH...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61920</th>\n",
       "      <td>MAVKTGIAIGLNKGKKVTQMTPAPKISYKKGAASNRTKFVRSLVRE...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHH...</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCTTCCCHHHHHHHHHHHH...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61921</th>\n",
       "      <td>RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...</td>\n",
       "      <td>CCCCHHHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>CCCCHHHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61922</th>\n",
       "      <td>RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...</td>\n",
       "      <td>CCCCCHHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>CCCCCHHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61923</th>\n",
       "      <td>RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...</td>\n",
       "      <td>CCCCCCHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>CCCCCCHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42386 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     seq  \\\n",
       "0                                                    EDL   \n",
       "1                                                    KCK   \n",
       "2                                                    KAK   \n",
       "3                                                    KFK   \n",
       "5                                                    KMK   \n",
       "...                                                  ...   \n",
       "61918  MAVKTGIAIGLNKGKKVTQMTPAPKISYKKGAASNRTKFVRSLVRE...   \n",
       "61920  MAVKTGIAIGLNKGKKVTQMTPAPKISYKKGAASNRTKFVRSLVRE...   \n",
       "61921  RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...   \n",
       "61922  RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...   \n",
       "61923  RYNDYKLDFRRQQMQDFFLAHKDEEWFRSKYHPDEVGKRRQEARGA...   \n",
       "\n",
       "                                                    sst3  \\\n",
       "0                                                    CEC   \n",
       "1                                                    CEC   \n",
       "2                                                    CEC   \n",
       "3                                                    CEC   \n",
       "5                                                    CEC   \n",
       "...                                                  ...   \n",
       "61918  CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHH...   \n",
       "61920  CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCHHHHHHHHHHHH...   \n",
       "61921  CCCCHHHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...   \n",
       "61922  CCCCCHHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...   \n",
       "61923  CCCCCCHHHHHHHHHHHHHHCCCCHHHHHHHCHHHHHHHHHHHHHH...   \n",
       "\n",
       "                                                    sst8  remove  len  \n",
       "0                                                    CBC       0    3  \n",
       "1                                                    CBC       0    3  \n",
       "2                                                    CBC       0    3  \n",
       "3                                                    CBC       0    3  \n",
       "5                                                    CBC       0    3  \n",
       "...                                                  ...     ...  ...  \n",
       "61918  CCCCCCCCCCCCCCCCCCCCCCCCCCCCSCCCCCHHHHHHHHHHHH...       0  100  \n",
       "61920  CCCCCCCCCCCCCCCCCCCCCCCCCCCCCTTCCCHHHHHHHHHHHH...       0  100  \n",
       "61921  CCCCHHHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...       0  100  \n",
       "61922  CCCCCHHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...       0  100  \n",
       "61923  CCCCCCHHHHHHHHHHHHHHTSSCHHHHHHHCHHHHHHHHHHHHHH...       0  100  \n",
       "\n",
       "[42386 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"len\"] = sample[\"seq\"].apply(len)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/input_char2index.json') as f:\n",
    "    input_word2index = json.load(f)\n",
    "\n",
    "with open('../static/input_index2char.json') as f:\n",
    "    input_index2word = json.load(f)\n",
    "\n",
    "\n",
    "with open('../static/output_char2index8.json') as f:\n",
    "    output_word2index = json.load(f)\n",
    "\n",
    "with open('../static/output_index2char8.json') as f:\n",
    "    output_index2word = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, word2index={}, index2word= {0: \"SOS\"}):\n",
    "        self.word2index = word2index\n",
    "        self.word2count = {}\n",
    "        self.index2word = index2word\n",
    "        self.n_words = len(self.index2word)\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in list(sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            if word not in self.word2count:\n",
    "                self.word2count[word] = 1\n",
    "            else:\n",
    "                self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:\n",
      "Sequence: 22\n",
      "Structure: 9\n",
      "('GPSQPKVPEWVNTPSTCCLKYYEKVLPRRLVVGYRKALNCHLPAIIFVTKRNREVCTNPNDDWVQEYIKDPNLPLLPTRNLSTVKIITAKNGQPQLLNSQ', 'CCCCCCCCCCCCSCEEECSSCCSSCCCGGGEEEEEEETTSSSCEEEEEETTSCEEEECTTSHHHHHHHTCTTCCBCCCCCCCCCCCCCCCCCCCCCCCCC')\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, input_word2index, input_index2word,output_word2index,output_index2word):\n",
    "\n",
    "    input_lang = Lang(input_word2index, input_index2word)\n",
    "    output_lang = Lang(output_word2index,output_index2word) \n",
    "\n",
    "    pairs = list(zip(lang1,lang2))\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    print(\"Counted words:\")\n",
    "    print(f\"Sequence: {input_lang.n_words}\")\n",
    "    print(f\"Structure: {output_lang.n_words}\")\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(sample[\"seq\"], sample[\"sst8\"],input_word2index, input_index2word,output_word2index,output_index2word)\n",
    "\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = sample[\"len\"].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in list(sentence)]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "n = len(pairs)\n",
    "input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "for idx, (inp, tgt) in enumerate(pairs):\n",
    "    inp_ids = indexesFromSentence(input_lang, inp)\n",
    "    tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "    input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "    target_ids[idx, :len(tgt_ids)] = tgt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(input_ids)*0.6)\n",
    "test_size = int(len(input_ids)*0.2)\n",
    "\n",
    "X = input_ids\n",
    "y = target_ids\n",
    "\n",
    "X_train = torch.tensor(X[:train_size], dtype=torch.long)\n",
    "y_train = torch.tensor(y[:train_size],dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X[train_size:train_size+test_size],dtype=torch.long)\n",
    "y_test = torch.tensor(y[train_size:train_size+test_size],dtype=torch.long)\n",
    "\n",
    "X_val = torch.tensor(X[train_size+test_size:],dtype=torch.long)\n",
    "y_val = torch.tensor(y[train_size+test_size:],dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_freq = (torch.tensor(y, dtype=torch.long).shape[0] * torch.tensor(y, dtype=torch.long).shape[1]) - torch.count_nonzero(torch.tensor(y, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6514e-04, 5.4273e-04, 1.4653e-02, 9.1033e-04, 1.6556e-03, 1.8337e-03,\n",
      "        7.0960e-03, 5.4944e-04, 9.7249e-01])\n"
     ]
    }
   ],
   "source": [
    "vocab = output_lang.word2index\n",
    "word_freq = output_lang.word2count\n",
    "\n",
    "vocab.update({\"SOS\":0})\n",
    "word_freq.update({\"SOS\":int(SOS_freq)})\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "weights = torch.zeros(vocab_size)\n",
    "\n",
    "for word, idx in vocab.items():\n",
    "    weights[idx] = 1.0 / (word_freq[word]) \n",
    "    \n",
    "weights = weights / weights.sum()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inpit_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embed = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = F.relu(x)\n",
    "        x , hidden = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        x = F.log_softmax(x, dim = -1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 13, 18, 13, 13, 18, 12, 14,  4,  3,  1, 18, 18,  6,  6, 14, 12, 14,\n",
       "        13,  3,  3, 10, 13, 21,  2,  6, 12,  6, 18, 14, 18, 18,  9, 15, 18, 10,\n",
       "        14, 15, 11,  1, 14, 11, 11, 16, 13, 12, 18, 17,  1,  7, 14, 18, 12, 11,\n",
       "        13,  4, 13, 14,  6, 14, 10, 13, 11,  3,  4, 12, 11, 18,  2, 15, 14, 10,\n",
       "        14, 18, 15, 14,  8, 15, 15, 13, 15, 13,  2,  3, 15, 13, 15, 13, 13, 12,\n",
       "        10, 13, 10, 16, 15, 19, 14,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 5, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3,\n",
       "        3, 1, 1, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 1, 1, 1, 1, 3,\n",
       "        3, 3, 3, 3, 3, 4, 4, 1, 1, 3, 3, 3, 3, 1, 5, 1, 1, 4, 4, 1, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3,\n",
       "        1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "batch_size = 128\n",
    "hidden_size = 256\n",
    "n_epochs = 100\n",
    "\n",
    "patience = 5\n",
    "best_result = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(list(zip(X_train,y_train)), batch_size=batch_size)\n",
    "test_loader = DataLoader(list(zip(X_test,y_test)), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_lang.n_words, 64, hidden_size, output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 1.6969677504867013, Test loss: 1.6217074394226074\n",
      "Epoch: 1, Train loss: 1.539151581850919, Test loss: 1.5294550657272339\n",
      "Epoch: 2, Train loss: 1.4470167948742105, Test loss: 1.4659918546676636\n",
      "Epoch: 3, Train loss: 1.3644175165229373, Test loss: 1.44328773021698\n",
      "Epoch: 4, Train loss: 1.2911029497180322, Test loss: 1.3245487213134766\n",
      "Epoch: 5, Train loss: 1.2092470466488539, Test loss: 1.2775790691375732\n",
      "Epoch: 6, Train loss: 1.13335273753513, Test loss: 1.2493984699249268\n",
      "Epoch: 7, Train loss: 1.0429179873129335, Test loss: 1.2482428550720215\n",
      "Epoch: 8, Train loss: 1.0294994323542623, Test loss: 1.1932414770126343\n",
      "Epoch: 9, Train loss: 0.9872657710855658, Test loss: 1.152303695678711\n",
      "Epoch: 10, Train loss: 0.8999971294342869, Test loss: 1.1191556453704834\n",
      "Epoch: 11, Train loss: 0.8424947809691381, Test loss: 1.0925854444503784\n",
      "Epoch: 12, Train loss: 0.7937890075974994, Test loss: 1.0788254737854004\n",
      "Epoch: 13, Train loss: 0.7522346306629856, Test loss: 1.0633337497711182\n",
      "Epoch: 14, Train loss: 0.7164699162798699, Test loss: 1.054291009902954\n",
      "Epoch: 15, Train loss: 0.6861029878409222, Test loss: 1.0506080389022827\n",
      "Epoch: 16, Train loss: 0.6656590235052686, Test loss: 1.0511733293533325\n",
      "Epoch: 17, Train loss: 0.6453643231981933, Test loss: 1.0547868013381958\n",
      "Epoch: 18, Train loss: 0.6239462558067206, Test loss: 1.0475735664367676\n",
      "Epoch: 19, Train loss: 0.6042836002930246, Test loss: 1.0505800247192383\n"
     ]
    }
   ],
   "source": [
    "test_loss_array = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(X_batch)\n",
    "\n",
    "        loss = loss_fn(output.permute(1,2,0), y_batch.permute(1,0))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "\n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  \n",
    "\n",
    "        for X_batch, y_batch in test_loader:\n",
    "\n",
    "            output = model(X_batch)\n",
    "            loss = loss_fn(output.permute(1,2,0), y_batch.permute(1,0))\n",
    "\n",
    "            test_loss+=loss\n",
    "\n",
    "    loss = total_loss / (len(X_train) // batch_size)\n",
    "    loss_test = test_loss / (len(y_test) // batch_size)\n",
    "\n",
    "    test_loss_array.append(loss_test)\n",
    "\n",
    "    if loss_test < best_result:\n",
    "        torch.save(model.state_dict(), \"../Models/lstm_8.pth\")\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train loss: {loss}, Test loss: {loss_test}\")\n",
    "\n",
    "    if len(test_loss_array)>patience+1:\n",
    "        if not (any(x > (test_loss_array[-1]+0.015) for x in test_loss_array[len(test_loss_array)-patience-1:-1])):\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embed): Embedding(22, 64)\n",
       "  (lstm): LSTM(64, 256, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../Models/lstm_8.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    outputs_pred = model(X_val)\n",
    "\n",
    "    _, topi = outputs_pred.topk(1)\n",
    "    decoded_ids = topi.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCCEEEEBCTTSSSSEEEEESSCSCECSSEEECCSCCCTCEEEETSEEEECCCCBTSSEEEEEEBCTTBBCCCCSSCCCCGC', 'CEEEEEEBTSBSSEEEEEBBSSBBBSTBSEEEEEEEEETSTCTTTSEBETTSBBCCTTCBBESSBBCHHHHHHHHTSCSEEEEEEESTCCCCCCCCC', 'CCCHHHHHHHHCCSTSSSCBBHHHHHHHHHHTTSSSHHHHHHHHTHSTSSSSSSBHHHHHHHHTTSSTTBBHHGGGGC', 'CCSSCCEESSSGSTSTTCBEEHHHHHTTTTSSSSSSBSTTSSBCTTTBSTGGGTSSCBEHHETHBTTTTGHTHTTTEEEEECCSSCC', 'CEEEESSCBCCSSSTBCCBCTTCEEEEEECSSSSEEEEEETTTCCEEEEEGGGEEEC']\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for idx in decoded_ids:\n",
    "    decoded_structure = []\n",
    "    for id in idx:\n",
    "        if id.item() == SOS_token:\n",
    "            break\n",
    "        decoded_structure.append(output_lang.index2word[str(id.item())])\n",
    "    pred.append(\"\".join(decoded_structure))\n",
    "\n",
    "print(pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CEEEEEEEEEEEBSSCCEEEEGGGTCCSSEEECCCCCSSSSEEEEEEEEEETTHHHHSCCEEEEEETTTTEEEEEECCCCCC', 'CEEEECCBTTBTSEEEEESTTCCSBTTBCSEEEEEECTTCHHHHTCCCCTTCEEEEETTEECTTCCHHHHHHHHHSCCSCEEEEEECCSSSCCCCCC', 'CCCHHHHHHHHHCTTCSSEECHHHHHHHHHHHHTCCHHHHHHHHHHHCTTCSSSEEHHHHHHHHHHCHHHHHHHHTTC', 'CCCBCCCTTCTTCSSCCSHHHHHHHHHHHHCGGGSCCCHHHHHHHCCBSCSCTTCCCBCGGGCCCCHHHHHHHHHHHTTSCCSCBCC', 'CCCEESSCBCCCSTTBCCBCTTCBCCEEECTTSSEEEEECTTTCCEEEEEGGGEECC']\n"
     ]
    }
   ],
   "source": [
    "target=[]\n",
    "for idx in y_val:\n",
    "    decoded_structure = []\n",
    "    for id in idx:\n",
    "        if id.item() == SOS_token:\n",
    "            break\n",
    "        decoded_structure.append(output_lang.index2word[str(id.item())])\n",
    "    target.append(\"\".join(decoded_structure))\n",
    "\n",
    "print(target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are significantly lower than with SST3 model. They would definitely require improvements in further steps but for now this model will be used with the app with and users will be informed that this model is less accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character-level accuracy: 64.07956678825676%\n",
      "Character-level f1: 45.40226884967352%\n",
      "Exact match: 0.21231422505307856%\n"
     ]
    }
   ],
   "source": [
    "def char_level_metrics(predictions, targets):\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    for pred, target in zip(list(predictions), list(targets)):\n",
    "        if len(pred)<len(target):\n",
    "            pred = pred + (\"$\" * (len(target)-len(pred)))\n",
    "        if len(pred)>len(target):\n",
    "            target = target + (\"$\" * (len(pred)-len(target)))\n",
    "\n",
    "        accuracy += accuracy_score(list(pred),list(target))\n",
    "        f1 += f1_score(list(pred),list(target), average=\"macro\")\n",
    "\n",
    "    return accuracy/len(predictions), f1/len(predictions)\n",
    "\n",
    "ac, f1 = char_level_metrics(pred, target)\n",
    "\n",
    "print(f'Character-level accuracy: {ac*100}%')\n",
    "print(f'Character-level f1: {f1*100}%')\n",
    "print(f'Exact match: {accuracy_score(pred,target)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
